====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	2048
SRAM OFMAP (kB): 	6144
Dataflow: 	Output Stationary
CSV file path: 	./gpt2-xl(1558M)_1600_25_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 67584
Compute cycles: 2043
Stall cycles: 0
Overall utilization: 0.05%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 0.031 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 67584
Compute cycles: 2043
Stall cycles: 0
Overall utilization: 0.05%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 0.488 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2585088
Compute cycles: 25038
Stall cycles: 0
Overall utilization: 0.16%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 0.763 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Attention Cycles: 102150
Total Compute Cycles: 256464
Attention %: 0.39830151600224595
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 1024
Configuration: gpt2-xl(1558M)_1600_25_1024


************ SCALE SIM Run Complete ****************


