


Total Attention Cycles: 18384
Total Compute Cycles: 61328
Attention %: 0.2997651969736499
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 128
Configuration: gpt2-small(124M)_768_12_128






Total Attention Cycles: 30640
Total Compute Cycles: 147216
Attention %: 0.2081295511357461
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 256
Configuration: gpt2-large(774M)_1280_20_256






Total Attention Cycles: 73608
Total Compute Cycles: 121154
Attention %: 0.6075573237367318
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 1024
Configuration: gpt2-small(124M)_768_12_1024






Total Attention Cycles: 38300
Total Compute Cycles: 265324
Attention %: 0.14435181137024922
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 128
Configuration: gpt2-xl(1558M)_1600_25_128






Total Attention Cycles: 153350
Total Compute Cycles: 384976
Attention %: 0.39833651967914885
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 1024
Configuration: gpt2-xl(1558M)_1600_25_1024






Total Attention Cycles: 24512
Total Compute Cycles: 99670
Attention %: 0.245931574194843
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 128
Configuration: gpt2-medium(355M)_1024_16_128






Total Attention Cycles: 147240
Total Compute Cycles: 200922
Attention %: 0.7328216919998806
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 2048
Configuration: gpt2-small(124M)_768_12_2048






Total Attention Cycles: 38300
Total Compute Cycles: 265324
Attention %: 0.14435181137024922
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 256
Configuration: gpt2-xl(1558M)_1600_25_256






Total Attention Cycles: 36792
Total Compute Cycles: 81270
Attention %: 0.45271317829457364
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 512
Configuration: gpt2-small(124M)_768_12_512






Total Attention Cycles: 76650
Total Compute Cycles: 305208
Attention %: 0.2511402060234332
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 512
Configuration: gpt2-xl(1558M)_1600_25_512






Total Attention Cycles: 18384
Total Compute Cycles: 61328
Attention %: 0.2997651969736499
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 256
Configuration: gpt2-small(124M)_768_12_256






Total Attention Cycles: 196320
Total Compute Cycles: 282216
Attention %: 0.6956373841313037
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 2048
Configuration: gpt2-medium(355M)_1024_16_2048






Total Attention Cycles: 49056
Total Compute Cycles: 125748
Attention %: 0.39011356045424184
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 512
Configuration: gpt2-medium(355M)_1024_16_512






Total Attention Cycles: 306750
Total Compute Cycles: 544512
Attention %: 0.5633484661495064
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 2048
Configuration: gpt2-xl(1558M)_1600_25_2048






Total Attention Cycles: 294504
Total Compute Cycles: 360458
Attention %: 0.8170272264729871
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 4096
Configuration: gpt2-small(124M)_768_12_4096






Total Attention Cycles: 24512
Total Compute Cycles: 99670
Attention %: 0.245931574194843
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 256
Configuration: gpt2-medium(355M)_1024_16_256






Total Attention Cycles: 613550
Total Compute Cycles: 863584
Attention %: 0.7104693926705451
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 4096
Configuration: gpt2-xl(1558M)_1600_25_4096






Total Attention Cycles: 392672
Total Compute Cycles: 490840
Attention %: 0.8
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 4096
Configuration: gpt2-medium(355M)_1024_16_4096






Total Attention Cycles: 245400
Total Compute Cycles: 372714
Attention %: 0.658413689853346
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 2048
Configuration: gpt2-large(774M)_1280_20_2048






Total Attention Cycles: 122680
Total Compute Cycles: 243858
Attention %: 0.5030796611142551
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 1024
Configuration: gpt2-large(774M)_1280_20_1024






Total Attention Cycles: 490840
Total Compute Cycles: 630426
Attention %: 0.7785846395929102
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 4096
Configuration: gpt2-large(774M)_1280_20_4096






Total Attention Cycles: 98144
Total Compute Cycles: 177904
Attention %: 0.5516683154959978
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 1024
Configuration: gpt2-medium(355M)_1024_16_1024






Total Attention Cycles: 61320
Total Compute Cycles: 179430
Attention %: 0.34174887142618293
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 512
Configuration: gpt2-large(774M)_1280_20_512






Total Attention Cycles: 30640
Total Compute Cycles: 147216
Attention %: 0.2081295511357461
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 128
Configuration: gpt2-large(774M)_1280_20_128



