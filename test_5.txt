====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	1024
SRAM OFMAP (kB): 	6144
Dataflow: 	Weight Stationary
CSV file path: 	./gpt2-xl(1558M)_1600_25_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 65536
Compute cycles: 1789
Stall cycles: 0
Overall utilization: 0.06%
Mapping efficiency: 0.10%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 0.061 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 65536
Compute cycles: 3319
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 0.39%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 0.976 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 2560000
Compute cycles: 16561
Stall cycles: 0
Overall utilization: 0.24%
Mapping efficiency: 0.35%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 1.525 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Attention Cycles: 127700
Total Compute Cycles: 232174
Attention %: 0.5500185205923144
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 1024
Configuration: gpt2-xl(1558M)_1600_25_1024


************ SCALE SIM Run Complete ****************


