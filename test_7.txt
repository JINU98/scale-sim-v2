====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	128x128
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	512
SRAM OFMAP (kB): 	6144
Dataflow: 	Weight Stationary
CSV file path: 	./gpt2-xl(1558M)_1600_25_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 65536
Compute cycles: 1405
Stall cycles: 0
Overall utilization: 0.28%
Mapping efficiency: 0.39%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 0.122 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  512
self.ofmap_sram_write 65536
Compute cycles: 3567
Stall cycles: 0
Overall utilization: 0.11%
Mapping efficiency: 0.78%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 1.950 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  20800
self.ofmap_sram_write 2560000
Compute cycles: 25765
Stall cycles: 0
Overall utilization: 0.61%
Mapping efficiency: 0.75%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 3.048 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle


----------------------------------------------------------------------------------------


Total Attention Cycles: 124300
Total Compute Cycles: 283862
Attention %: 0.4378888333063249
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 1024
Configuration: gpt2-xl(1558M)_1600_25_1024


************ SCALE SIM Run Complete ****************


