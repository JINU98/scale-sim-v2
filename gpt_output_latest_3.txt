====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_128.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 128
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  128
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.020 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 42944
Total Attention Cycles: 1532
Attention %: 0.03567436661698957
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 128
Configuration: gpt2-small(124M)_768_12_128


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_256.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 256
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.041 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 116576
Total Attention Cycles: 1532
Attention %: 0.013141641504254736
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 256
Configuration: gpt2-large(774M)_1280_20_256


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  256
self.ofmap_sram_write 1024
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  1024
self.ofmap_sram_write 256
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 47546
Total Attention Cycles: 6134
Attention %: 0.1290119042611366
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 1024
Configuration: gpt2-small(124M)_768_12_1024


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_128.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 128
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  128
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.020 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 227024
Total Attention Cycles: 1532
Attention %: 0.00674818521389809
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 128
Configuration: gpt2-xl(1558M)_1600_25_128


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  256
self.ofmap_sram_write 1024
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  1024
self.ofmap_sram_write 256
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 231626
Total Attention Cycles: 6134
Attention %: 0.02648234654140727
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 1024
Configuration: gpt2-xl(1558M)_1600_25_1024


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_128.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 128
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  128
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.020 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 75158
Total Attention Cycles: 1532
Attention %: 0.020383724952766174
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 128
Configuration: gpt2-medium(355M)_1024_16_128


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_2048.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  512
self.ofmap_sram_write 2048
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  2048
self.ofmap_sram_write 512
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.325 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 53682
Total Attention Cycles: 12270
Attention %: 0.22856823516262434
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 2048
Configuration: gpt2-small(124M)_768_12_2048


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_256.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 256
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.041 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 227024
Total Attention Cycles: 1532
Attention %: 0.00674818521389809
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 256
Configuration: gpt2-xl(1558M)_1600_25_256


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_512.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  128
self.ofmap_sram_write 512
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  512
self.ofmap_sram_write 128
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.081 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 44478
Total Attention Cycles: 3066
Attention %: 0.06893295561850803
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 512
Configuration: gpt2-small(124M)_768_12_512


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_512.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  128
self.ofmap_sram_write 512
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  512
self.ofmap_sram_write 128
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.081 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 228558
Total Attention Cycles: 3066
Attention %: 0.013414538104113617
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 512
Configuration: gpt2-xl(1558M)_1600_25_512


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_256.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 256
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.041 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 42944
Total Attention Cycles: 1532
Attention %: 0.03567436661698957
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 256
Configuration: gpt2-small(124M)_768_12_256


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_2048.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  512
self.ofmap_sram_write 2048
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  2048
self.ofmap_sram_write 512
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.325 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 85896
Total Attention Cycles: 12270
Attention %: 0.14284716401229394
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 2048
Configuration: gpt2-medium(355M)_1024_16_2048


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_512.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  128
self.ofmap_sram_write 512
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  512
self.ofmap_sram_write 128
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.081 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 76692
Total Attention Cycles: 3066
Attention %: 0.039978094194961664
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 512
Configuration: gpt2-medium(355M)_1024_16_512


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_2048.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  512
self.ofmap_sram_write 2048
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  2048
self.ofmap_sram_write 512
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.325 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 237762
Total Attention Cycles: 12270
Attention %: 0.051606228076816314
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 2048
Configuration: gpt2-xl(1558M)_1600_25_2048


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-small(124M)_768_12_4096.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  4096
self.ofmap_sram_write 1024
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.651 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  2304
self.ofmap_sram_write 2304
Compute cycles: 6902
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.122 words/cycle
Average Filter DRAM BW: 9.375 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 65954
Total Attention Cycles: 24542
Attention %: 0.37210783273190406
Model Name and Parameters gpt2-small(124M)
Embeddding Dimension: 768
Number of Heads: 12
Context Length 4096
Configuration: gpt2-small(124M)_768_12_4096


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_256.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 256
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  256
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.041 words/cycle
Average Filter DRAM BW: 2.604 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 75158
Total Attention Cycles: 1532
Attention %: 0.020383724952766174
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 256
Configuration: gpt2-medium(355M)_1024_16_256


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-xl(1558M)_1600_25_4096.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  4096
self.ofmap_sram_write 1024
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.651 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  11200
self.ofmap_sram_write 11200
Compute cycles: 37582
Stall cycles: 0
Overall utilization: 0.10%
Mapping efficiency: 79.72%
Average IFMAP DRAM BW: 0.254 words/cycle
Average Filter DRAM BW: 9.924 words/cycle
Average OFMAP DRAM BW: 254.545 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 250034
Total Attention Cycles: 24542
Attention %: 0.09815465096746842
Model Name and Parameters gpt2-xl(1558M)
Embeddding Dimension: 1600
Number of Heads: 25
Context Length 4096
Configuration: gpt2-xl(1558M)_1600_25_4096


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_4096.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  4096
self.ofmap_sram_write 1024
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.651 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 98168
Total Attention Cycles: 24542
Attention %: 0.25
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 4096
Configuration: gpt2-medium(355M)_1024_16_4096


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_2048.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  512
self.ofmap_sram_write 2048
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  2048
self.ofmap_sram_write 512
Compute cycles: 6135
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.325 words/cycle
Average Filter DRAM BW: 6.944 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 127314
Total Attention Cycles: 12270
Attention %: 0.09637588953296573
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 2048
Configuration: gpt2-large(774M)_1280_20_2048


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  256
self.ofmap_sram_write 1024
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  1024
self.ofmap_sram_write 256
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 121178
Total Attention Cycles: 6134
Attention %: 0.05061974945947284
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 1024
Configuration: gpt2-large(774M)_1280_20_1024


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_4096.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  1024
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  4096
self.ofmap_sram_write 1024
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.651 words/cycle
Average Filter DRAM BW: 8.333 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 139586
Total Attention Cycles: 24542
Attention %: 0.17581992463427565
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 4096
Configuration: gpt2-large(774M)_1280_20_4096


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-medium(355M)_1024_16_1024.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  256
self.ofmap_sram_write 1024
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  1024
self.ofmap_sram_write 256
Compute cycles: 3067
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  4096
self.ofmap_sram_write 4096
Compute cycles: 12271
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.163 words/cycle
Average Filter DRAM BW: 9.804 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 79760
Total Attention Cycles: 6134
Attention %: 0.07690571715145436
Model Name and Parameters gpt2-medium(355M)
Embeddding Dimension: 1024
Number of Heads: 16
Context Length 1024
Configuration: gpt2-medium(355M)_1024_16_1024


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_512.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  128
self.ofmap_sram_write 512
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  512
self.ofmap_sram_write 128
Compute cycles: 1533
Stall cycles: 0
Overall utilization: 0.03%
Mapping efficiency: 25.00%
Average IFMAP DRAM BW: 0.081 words/cycle
Average Filter DRAM BW: 5.208 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 118110
Total Attention Cycles: 3066
Attention %: 0.025958851917703835
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 512
Configuration: gpt2-large(774M)_1280_20_512


************ SCALE SIM Run Complete ****************


====================================================
******************* SCALE SIM **********************
====================================================
Array Size: 	256x256
SRAM IFMAP (kB): 	6144
SRAM Filter (kB): 	6144
SRAM OFMAP (kB): 	2048
Dataflow: 	Weight Stationary
CSV file path: 	/home/jmalekar/Documents/scale-sim-v2/topologies/decoder_models_new/gpt2-large(774M)_1280_20_128.csv
Working in ESTIMATE BANDWIDTH mode.
====================================================

Running Layer 0 : Q
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 1 : K
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 2 : V
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 3 : Attention_score
self.ifmap_sram_reads  64
self.ofmap_sram_write 128
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.010 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 128.000 words/cycle

Running Layer 4 : Attention_output
self.ifmap_sram_reads  128
self.ofmap_sram_write 64
Compute cycles: 766
Stall cycles: 0
Overall utilization: 0.02%
Mapping efficiency: 12.50%
Average IFMAP DRAM BW: 0.020 words/cycle
Average Filter DRAM BW: 1.302 words/cycle
Average OFMAP DRAM BW: 64.000 words/cycle

Running Layer 5 : Add_norm
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 6 : Dense_in
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle

Running Layer 7 : Dense_out
self.ifmap_sram_reads  6400
self.ofmap_sram_write 6400
Compute cycles: 19174
Stall cycles: 0
Overall utilization: 0.13%
Mapping efficiency: 100.00%
Average IFMAP DRAM BW: 0.203 words/cycle
Average Filter DRAM BW: 9.645 words/cycle
Average OFMAP DRAM BW: 256.000 words/cycle


----------------------------------------------------------------------------------------


Total Compute Cycles: 116576
Total Attention Cycles: 1532
Attention %: 0.013141641504254736
Model Name and Parameters gpt2-large(774M)
Embeddding Dimension: 1280
Number of Heads: 20
Context Length 128
Configuration: gpt2-large(774M)_1280_20_128


************ SCALE SIM Run Complete ****************


